{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DynamicSystems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheilKumar/DynamicSystemRNNs/blob/master/DynamicSystems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfELTXphq6Ps"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/drive/1FS3cBYRf83HTWo6J88kKAQr4kjgoIw_C#scrollTo=LfELTXphq6Ps\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/SheilKumar/DynamicSystemRNNs\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDARJJQ3sK55"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from scipy.integrate import odeint\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hMzdkxAR1MY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "03c36722-55ed-470c-8bf2-1226eca88d38"
      },
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.auto_scroll_threshold = 10;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cu8iHe4r1uD"
      },
      "source": [
        "___\n",
        "# 1.0 Lorentz System \n",
        "___\n",
        "The first system we will attempt to train our network to predict is the **Lorentz System**:\n",
        "\n",
        "![Alt Text](https://upload.wikimedia.org/wikipedia/commons/1/13/A_Trajectory_Through_Phase_Space_in_a_Lorenz_Attractor.gif)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGX6lHBdtPnK"
      },
      "source": [
        "# 1.1 Simulation of Lorentz System \n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGSqdnSIttIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "9c5be271-8fa9-4bcb-9a0e-13d9f3f125af"
      },
      "source": [
        "rho = 28.0\n",
        "sigma = 10.0\n",
        "beta = 8.0 / 3.0\n",
        "\n",
        "def f(state, t):\n",
        "    x, y, z = state  # Unpack the state vector\n",
        "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives\n",
        "\n",
        "state0 = [1.0, 1.0, 1.0]\n",
        "t = np.arange(0.0, 300.0, 0.01)\n",
        "\n",
        "states = odeint(f, state0, t)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(states[:, 0], states[:, 1], states[:, 2])\n",
        "plt.draw()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xibqDyUpPgS2"
      },
      "source": [
        "# 1.2 Training a Network \n",
        "\n",
        "In order to train an RNN, we need to first generate and split data from the Lorentz system into a training and testing set. We then need to create the structure of the LSTM that will be used. Finally we need to train the RNN and evaluate its results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls7_-VDcSZ6a"
      },
      "source": [
        "## 1.2.1 Generate and Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5vgaADqSbhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dbf0ae-f1ca-4441-e3e4-c28f7b016df5"
      },
      "source": [
        "# Genereate data\n",
        "# create vectors of the first 5 states and expected vector of the 6th state \n",
        "Data = [[states[i+j]/(100/0.1) for i in range(5)] for j in range(len(states)-5)] # Dividing by (100/0.1) to normalize the data\n",
        "Target = [states[i+5]/(100/0.1) for i in range(len(states)-5)]\n",
        "data = np.array(Data, dtype=float)\n",
        "target = np.array(Target, dtype=float)\n",
        "print(data.shape,target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyqe9yLKWAIt"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpbUfF9sWpTi"
      },
      "source": [
        "## 1.2.2 Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3tf5VXWxc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b15e465-d8a6-4539-e94b-a96876f5108d"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM((3),batch_input_shape=(None,5,3),return_sequences=True))\n",
        "model.add(LSTM((3),return_sequences=False))\n",
        "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wPmsGp_YWxu"
      },
      "source": [
        "## 1.2.3 Train Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB6BITI_X-sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4efb39-0c1a-4e93-9b43-a7c72995dc63"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9-RO9PkYOJ4"
      },
      "source": [
        "## 1.2.4 Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D93YFr3MYp_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a0089d35-5c93-4e48-ac02-5f23b03c868c"
      },
      "source": [
        "results = model.predict(x_test)\n",
        "#x values\n",
        "plt.scatter(range(500),results[0:500,0],c='r')\n",
        "plt.scatter(range(500),y_test[0:500,0],c='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIY0uktOdIsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5be921e2-3f0f-4475-b607-e25ae4f9eefc"
      },
      "source": [
        "#y values\n",
        "plt.scatter(range(500),results[0:500,1],c='r')\n",
        "plt.scatter(range(500),y_test[0:500,1],c='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fG9mzRbdMtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "10d525ea-0628-46f0-a091-d01fbe59d83f"
      },
      "source": [
        "#z values\n",
        "plt.scatter(range(500),results[0:500,1],c='r')\n",
        "plt.scatter(range(500),y_test[0:500,1],c='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohwaAddubupD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0fa6ff11-8b62-442d-b0fc-1905559ee2e0"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT9PSr_3cPh7"
      },
      "source": [
        "As can be seen by the two plots, our model is able to predict the next state of the system with great accuracy and the loss is almost stagnant by 40 epochs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0aiAmbxl4C"
      },
      "source": [
        "## 1.2.5 Closing the Loop \n",
        "\n",
        "We will attempt to use the model to complete the loop and attain a similar image as shown in section 1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb136P4tLYBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663c9743-6bc8-446c-fb46-cbf8c04695d9"
      },
      "source": [
        "np.array(Data).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECtECl81x0BB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "dba786ce-1eee-4055-9cd1-496004e5f89a"
      },
      "source": [
        "x_range = np.array(Data[0:5000])\n",
        "y_range = model.predict(x_range)\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(y_range[:, 0]*1000, y_range[:, 1]*1000, y_range[:, 2]*1000)\n",
        "plt.draw()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyC7oLFXzhrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46e1ad6-d16c-403a-ea30-2f05d4404b3d"
      },
      "source": [
        "new_data = np.array([[y_range[i+j]for i in range(5)] for j in range(1)])\n",
        "y_new = []\n",
        "new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntFA34omF5V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b742e3b0-b99f-4d7a-b085-6d4077552537"
      },
      "source": [
        "states[-6:],current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0KjwBgjEm0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b659ef-23c8-46d9-b743-76c23f50ddf7"
      },
      "source": [
        "\n",
        "current = np.array([states[-6:-1]])/1000\n",
        "model.predict(current)*1000-states[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6Bco8HFV0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74578ef5-214f-47ba-eac8-2782037889f2"
      },
      "source": [
        "hist=30\n",
        "current = np.array([states[-hist:-hist+5]])/1000\n",
        "for i in range(hist-5):\n",
        "  current[0,:4]= current[0,1:]\n",
        "  current[0,4] = model.predict(current)\n",
        "  print(current[0,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3L16-84KRsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6031face-4d40-424d-acec-766358c693f7"
      },
      "source": [
        "new_data, model.predict(new_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx-AHcIrKv4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140380ec-af10-4f76-c9e8-b3833ee8cfaa"
      },
      "source": [
        "y_range[:7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798cP82s3zGV"
      },
      "source": [
        "y_new=[]\n",
        "#giving the model only 5 previous states\n",
        "for i in range(50):\n",
        "  y_n = np.array(model.predict(new_data))\n",
        "  new_data[0][0:3] = new_data[0][1:4]\n",
        "  new_data[0][4] = y_n\n",
        "  y_new.append(y_n)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsliojb_Khk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93a5526-f976-4ff7-95ac-af0a391980c1"
      },
      "source": [
        "y_range[:7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA1VEG1SJHBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a6bff2-3802-456b-fc89-f93e53826b8b"
      },
      "source": [
        "y_new = np.array(y_new)\n",
        "new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FS9QrzuNrSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "f7045b41-21e5-4baa-d8aa-44af36349ba0"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(y_new[:, 0,0]*1000, y_new[:,0,1]*1000, y_new[:,0,2]*1000)\n",
        "plt.draw()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbbVj3YzOaFi"
      },
      "source": [
        "#giivng the model 100 previous states\n",
        "new_data = np.array([[y_range[i+j]for i in range(5)] for j in range(100)])\n",
        "y_new = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNO9aTRmOky0"
      },
      "source": [
        "for i in range(5000):\n",
        "  y_n = np.array(model.predict(new_data))\n",
        "  new_data[0:98] = new_data[1:99]\n",
        "  new_data[99][0:3] = new_data[99][1:4]\n",
        "  new_data[99][4] = y_n[-1]\n",
        "  y_new.append(y_n[-1])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX5rMQknTYsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "f073835b-84bc-42ff-a29a-3167234e3dad"
      },
      "source": [
        "y_new = np.array(y_new)\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(y_new[:,0]*1000, y_new[:,1]*1000, y_new[:,2]*1000)\n",
        "plt.draw()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCoUqPYa0PkG"
      },
      "source": [
        "# 2.0 Rethinking the Network\n",
        "\n",
        "In the previous iteration of our LSTM, our input consisted of the 5 previous states of the system, and we attempted to predict the next state from those previous states. As we saw from our result, while it worked well with the training data and the testing data. The network was unable to \"close the loop\"; it was unable to correctly reproduce the very first figure shown in **Section 1.1 Simulation of Lorentz System**. Therefore we must come up with a new idea for the network  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMhKkYF1L4d"
      },
      "source": [
        "# 2.1 Changing the output\n",
        "\n",
        "Now we will attempt to change the network such that it is trained to figure out the delta between the current and next states. That is, given states $A_1,A_2,...,A_n$ we will train the network to predict $A_{n+1}-A_n$. Our hope is that this methodology will make better use of the LSTM's architecture, that is, we hope that the LSTM's **gates** are more readily used to train the network more effectively. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpmTygOp2Otw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0575379a-9514-470b-f12b-546137ab65e3"
      },
      "source": [
        "#To generate new data, we can continue to use `states` from 1.1\n",
        "# create vectors of the first A_1,..,A_n states, and target vector which is A_{n+1}-A_n \n",
        "n = 100     #length of each input vector\n",
        "s = 1000    #number of input vectors\n",
        "Data = np.array([[states[i+j] for i in range(n)] for j in range(s)])\n",
        "Target = np.array([states[i+n]-states[i+n-1] for i in range(s)])\n",
        "Data.shape, Target.shape\n",
        "#[samples, time steps, features(x,y,z)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeVU1YUJ5dUF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "41312477-dc3e-49e7-bbc4-9deef7b7068c"
      },
      "source": [
        "Data[0][n-1], states[100]-states[99], Target[0] #checking the data is exactly what we want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95bYPNWd3TwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0c12d43-5c46-499b-adfa-ebec9abe8510"
      },
      "source": [
        "#split data into training and testing sets\n",
        "x_train,x_test,y_train,y_test = train_test_split(Data,Target,test_size=0.2,random_state=4)\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmu9n4Cf_zbb"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(\n",
        "    keras.layers.LSTM(units=50,return_sequences=True)\n",
        ")\n",
        "model2.add(keras.layers.Dropout(rate=0.2))\n",
        "model2.add(\n",
        "    keras.layers.LSTM(units=50)\n",
        ")\n",
        "model2.add(keras.layers.Dropout(rate=0.2))\n",
        "model2.add(keras.layers.Dense(units=3))\n",
        "model2.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxkxtdzgNAMs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b9d1f476-a95a-4ee9-c60e-7fec5275b3da"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbBoWrkWBUQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44267a10-0e88-416e-9c88-ed7ce111b8a9"
      },
      "source": [
        "history_model2 = model2.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sfn4P7dEm_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6239c9d0-fbb4-457e-fe3c-3ed4e0826643"
      },
      "source": [
        "y_pred2 = model2.predict(x_test)\n",
        "y_pred2[20], y_test[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pJaBM53KQrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "224ed729-3a15-43f9-c491-d73ed807cfa8"
      },
      "source": [
        "np.array(f(x_test[20][-1],1))*0.01,yt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZKrWSQGv_t"
      },
      "source": [
        " ## 2.1.1 Predicting on Unseen Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwdrbxUbG2vc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1c38d5b9-7925-401b-9a91-77ca5441ee68"
      },
      "source": [
        "# we need to create new data to see how \n",
        "np.random.seed(400)\n",
        "random_numbers = np.random.randint(1500,2000,size=50)\n",
        "new_data = np.array([[states[i+j] for i in range(n)] for j in random_numbers])\n",
        "new_target = np.array([states[i+n]-states[i+n-1] for i in random_numbers])\n",
        "random_pred = model2.predict(new_data)\n",
        "x = 0\n",
        "new_data[x][-1],random_pred[32],new_target[32]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-fNUVj5IdVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7de426db-ba8a-4873-8e6d-9c3aaa6a0ee8"
      },
      "source": [
        "random_numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkVf-FZXyf4"
      },
      "source": [
        "# 2.1.2 Evaluation \n",
        "\n",
        "It seems to be that the LSTM is still unable to accurately predict on unseen data. I believe that the reason for this might be due to the ranges of the values of the data being too great. So now we will attempt to use a scaler to transform all the values of the data t values between 0 and 1 and then inverse transform the values back after modelling. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS_CMoYiYCYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f5828957-524a-4a50-eabe-153b353cdb29"
      },
      "source": [
        "z = np.array([0,12,4,546,5,3]).reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(z)\n",
        "scaler.inverse_transform(np.array([0.05,0.06,0.3,0.4]).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S45qSXaRbdDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc3b17ae-671d-4896-a551-36c4deb212b5"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li4h6OJMbmnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0165d09-102b-4243-ac57-20e7b20c1a83"
      },
      "source": [
        "def generator2():\n",
        "    for i in range(10):\n",
        "        yield i\n",
        "\n",
        "o = generator2()\n",
        "o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ-z2_XobKEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ef9ac286-41e0-4f25-8264-31eab8edcb2f"
      },
      "source": [
        "for i in o:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu-Klp_cbfwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f3106e6-a06e-418b-d58b-4ff3bf153340"
      },
      "source": [
        "o.__next__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-4-ZFypZrNQ"
      },
      "source": [
        "This range is too much for the LSTM to be trained on we need to scale values between 0 and 1 or -1 and 1. So that the network is able to learn better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJm6pZNR8gOL"
      },
      "source": [
        "# 3.1 Creating from scratch \n",
        "\n",
        "**1.** Generate Window function \n",
        "\n",
        "* Input:\n",
        "    * Data (Complete Dataset)\n",
        "    * Batch Size\n",
        "    * Time Steps \n",
        "\n",
        "* Output:\n",
        "    * X and Y Datasets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Same as 1.0 adding for ease of access\n",
        "rho = 28.0\n",
        "sigma = 10.0\n",
        "beta = 8.0 / 3.0\n",
        "\n",
        "def f(state, t):\n",
        "    x, y, z = state  # Unpack the state vector\n",
        "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives\n",
        "\n",
        "state0 = [1.0, 1.0, 1.0]\n",
        "t = np.arange(0.0, 300.0, 0.01)\n",
        "\n",
        "states = odeint(f, state0, t)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(states[:, 0], states[:, 1], states[:, 2])\n",
        "plt.draw()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding states here for ease of access again. Same as in 1.0 \n",
        "rho = 28.0\n",
        "sigma = 10.0\n",
        "beta = 8.0 / 3.0\n",
        "\n",
        "def f(state, t):\n",
        "    x, y, z = state  # Unpack the state vector\n",
        "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives\n",
        "\n",
        "state0 = [1.0, 1.0, 1.0]\n",
        "t = np.arange(0.0, 300.0, 0.01)\n",
        "\n",
        "states = odeint(f, state0, t)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(states[:, 0], states[:, 1], states[:, 2])\n",
        "plt.draw()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBXaiyd29M-4"
      },
      "source": [
        "def get_window(data,batch_size, time_steps,start_id=1):\n",
        "  x_data = np.array([data[i+start_id:i+start_id+time_steps] for i in range(batch_size) ])\n",
        "  y_data = np.array([data[i+start_id+1:i+start_id+time_steps+1]-data[i+start_id:i+start_id+time_steps]for i in range(batch_size)])\n",
        "  x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2,shuffle=False)\n",
        "  return x_train,x_test,y_train,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZugQhCd90I1"
      },
      "source": [
        "#testin get_window\n",
        "np.random.seed(2808)\n",
        "x_train,x_test,y_train,y_test = get_window(states,16000,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uBMtKTFmy6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83053b60-c973-4b68-d34c-242a781116bc"
      },
      "source": [
        "x_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUd_GSb3Bb1l"
      },
      "source": [
        "lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.Dense(units=3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEUwXR-8DbFz"
      },
      "source": [
        "lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=[tf.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsvjrrumEljI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ed13cd-5908-49dc-c908-e0c8bca355fc"
      },
      "source": [
        "history = lstm_model.fit(x_train,y_train, epochs=25, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSaod4U0ZcTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2c05b6-b623-40a2-b628-208f1c5f967a"
      },
      "source": [
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkl7VJe2FKs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7be54b5-2899-418e-8f7f-999c50d865c8"
      },
      "source": [
        "lstm_model.predict(x_test)[1:10,:,:]+x_test[0:9,:,:], x_test[1:10,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlsyMJQMG5Ro"
      },
      "source": [
        "## 3.2 Predicting on Random Data Again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et3Yvn7ZG-pm"
      },
      "source": [
        "new_data = get_window(states,100,100,2400)\n",
        "x_new_data = new_data[0]\n",
        "pred_new_data = lstm_model.predict(x_new_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAHPs-5kI8Im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2e158a72-7331-4ffd-c80b-95bb0323a885"
      },
      "source": [
        "t = np.arange(0,99,1)\n",
        "\n",
        "plt.plot(t,pred_new_data[0,1:100,0]+x_new_data[0,0:99,0],'r--',label='Predicted')\n",
        "plt.plot(t,x_new_data[0,1:100,0],'b-',label='Actual')\n",
        "plt.xlabel('Index Value')\n",
        "plt.ylabel('Cell Value')\n",
        "plt.title('Comparing Predicted and Actual Values on unseen Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVKLxVcvajAG"
      },
      "source": [
        "## 3.3 Closing the Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr5Li-EaIGEd"
      },
      "source": [
        "def teach_lstm(data,start_index,model,trans=400):\n",
        "  for i in range(trans):\n",
        "    model.predict(tf.expand_dims(tf.expand_dims(data[start_index-trans+i],0),0))\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31WLA2ceMLcy"
      },
      "source": [
        "def close_loop(data,num_loops,model,start_index,trans=400):\n",
        "  teach_lstm(data,start_index,model,trans)\n",
        "  old_state = tf.expand_dims(tf.expand_dims(data[start_index],0),0)\n",
        "  predicted_states = []\n",
        "  for i in range(num_loops):\n",
        "    new_state = model.predict(old_state)+old_state\n",
        "    old_state = new_state\n",
        "    predicted_states.append(np.squeeze(np.squeeze(old_state,0),0))\n",
        "  return np.array(predicted_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zamuu157oHpY"
      },
      "source": [
        "init_state = 25000\n",
        "loops = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqFdaEV5lurD"
      },
      "source": [
        "test = close_loop(states,loops,lstm_model,init_state,400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkg0PUwpLcN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb317a9b-1f4c-44e1-c45c-f93a59164062"
      },
      "source": [
        "test-states[init_state:init_state+loops]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EINzdIHkjOpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "87d9db69-bbae-4cec-b13e-c92028c12872"
      },
      "source": [
        "coord = 2\n",
        "\n",
        "plt.plot(test[:,coord],'r--',label='Predicted')\n",
        "plt.plot(states[init_state+1:init_state+loops+1,coord],'b-',label='Actual')\n",
        "plt.plot(test[:,coord]-states[init_state+1:init_state+loops+1,coord],'y-',label=\"Difference\")\n",
        "plt.xlabel('Index Number')\n",
        "plt.ylabel('Cell Value')\n",
        "plt.title('Comparing Predicted and Actual Values on unseen z-coordinate Data')\n",
        "plt.legend()\n",
        "#images_dir = '/content/gdrive/My Drive'\n",
        "#plt.savefig(f\"{images_dir}/z_coord.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK7P8XgMmhH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c7f12004-37ad-481f-f30b-ba06924c48d5"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "ax.plot(test[:,0], test[:, 1], test[:,2])\n",
        "plt.draw()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt6sngoPSG6x"
      },
      "source": [
        "# Progress Report \n",
        "\n",
        "This excerpt shall serve as a reminder for all the work done so far. It will also help guide further progress and can serve as a baseline if one is to forget anything moving forward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJVJCm6WZjTY"
      },
      "source": [
        "## Data Structure \n",
        "\n",
        "```python\n",
        "def get_window(data,batch_size, time_steps,start_id=1):\n",
        "  x_data = np.array([data[i+start_id:i+start_id+time_steps] for i in range(batch_size) ])\n",
        "  y_data = np.array([data[i+start_id+1:i+start_id+time_steps+1]-data[i+start_id:i+start_id+time_steps]for i in range(batch_size)])\n",
        "  x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2,shuffle=False)\n",
        "  return x_train,x_test,y_train,y_test\n",
        "```\n",
        "Function used to create the data for training and testing. \n",
        "\n",
        "* **Inputs**: \n",
        "    * `data`: Array containing data from the Lorentz Attractor. \n",
        "    * `batch_size`: Number of training batches to be created.\n",
        "    * `time_steps`: Number of consecutive time steps per batch. $\\Delta t$ = 0.01\n",
        "    * `start_id`: Index number of `data` to begin creating training and testing sets from. \n",
        "\n",
        "![](https://i.imgur.com/oprpK6v.jpeg)\n",
        "\n",
        "* **Outputs**\n",
        "    * `x_train`: Input data to train the network.\n",
        "    * `x_test`: Validation input data to test the network\n",
        "    * `y_train`: Target data to train the network.\n",
        "    * `y_test`: Validation target data to test the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_AM4J0rZwUM"
      },
      "source": [
        "## Network Architecture \n",
        "\n",
        "```python\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.Dense(units=3)\n",
        "])\n",
        "```\n",
        "\n",
        "\n",
        "* Cell type: LSTM\n",
        "* RNN Units: 256 \n",
        "* Dense Layer: 3 Neurons \n",
        "* Input Shape: \\[X,1,3\\] X=12,800 during training \n",
        "* Output Shape: \\[X,1,3\\]\n",
        "\n",
        "The network is currently given 12,800 individual points to be trained. "
      ]
    },
    {
      "source": [
        "* LSTM Parameters = $4\\cdot(\\text{LSTM_units})\\cdot(\\text{LSTM_units}+\\text{num_features}+1))=4(256(256+3+3))$\n",
        "* Dense Parameters = $\\text{num_features}\\cdot(\\text{LSTM_units}+1)$\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BXyJE7XZ7Bx"
      },
      "source": [
        "## Training Parameters \n",
        "```python\n",
        "lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "```\n",
        "```python \n",
        "history = lstm_model.fit(x_train,y_train, epochs=30, validation_data=(x_test,y_test))\n",
        "```\n",
        "\n",
        "* Loss Function: Mean Squared Error\n",
        "* Optimizer = Adam \n",
        "* Metric = Mean Absolute Error \n",
        "* Epochs: 30 \n",
        "\n",
        "## Total Parameters \n",
        "\n",
        "* num_features = 3 (x,y,z)\n",
        "* LSTM_units = 256 (But can be changed in the future)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-LgAOfKaBvp"
      },
      "source": [
        "## Results \n",
        "\n",
        "The `teach_lstm` function is used to bring the LSTM internal state as close as possible to just before the data used for closing the loop. The `close_loop` function uses `teach_lstm` inside it before beginning to predicate states.\n",
        "\n",
        "```python\n",
        "def teach_lstm(data,start_index,model,trans=400):\n",
        "  for i in range(trans):\n",
        "    model.predict(tf.expand_dims(tf.expand_dims(data[start_index-trans+i],0),0))\n",
        "  return None\n",
        "```\n",
        "```python\n",
        "def close_loop(data,num_loops,model,start_index,trans=400):\n",
        "  teach_lstm(data,start_index,model,trans)\n",
        "  old_state = tf.expand_dims(tf.expand_dims(data[start_index],0),0)\n",
        "  predicted_states = []\n",
        "  for i in range(num_loops):\n",
        "    new_state = model.predict(old_state)+old_state\n",
        "    old_state = new_state\n",
        "    predicted_states.append(np.squeeze(np.squeeze(old_state,0),0))\n",
        "  return np.array(predicted_states)\n",
        "```\n",
        "\n",
        "* **Inputs**:\n",
        "    * `data`: Array containing data from the Lorentz attractor. \n",
        "    * `num_loops`: Number of states to be predicted.\n",
        "    * `model`: Model used to predict data.\n",
        "    * `start_index`: Index number of `data to begin predicting from. (Reccomended to used indexes greater than 16000 so that the model has not seen the points yet)\n",
        "    * `trans`: Number of previous states used to adjust the LSTM internal state. \n",
        "\n",
        "* **Outputs**:\n",
        "    * `predicted_states`: An `np.array` of predicted states.\n",
        "\n",
        "### Accuracy Tests \n",
        "\n",
        "Beginning with a starting index of 25000 and predicting 100 consecutive time steps. \n",
        "\n",
        "```python\n",
        "init_state = 25000\n",
        "loops = 100\n",
        "test = close_loop(states,loops,lstm_model,init_state,400)\n",
        "```\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/2zuy3Fx.png)\n",
        "![](https://i.imgur.com/qs76LGF.png)\n",
        "![](https://i.imgur.com/iGJGdHn.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}